<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>HAMMING</title>
</head>

<body>
	<pre>

# Imputation
import pandas as pd
from sklearn.impute import SimpleImputer
from scipy import stats
from sklearn.preprocessing import StandardScaler, MinMaxScaler
# Create the DataFrame
data = {
'Student ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
'Exam 1 Score': [85, 76, 90, 65, 88, None, 78, 92, 85, 70],
'Exam 2 Score': [92, 78, 88, 75, 91, 82, 76, 96, 89, 68],
'Exam 3 Score': [88, None, 94, 80, 87, 79, 72, 98, 91, 75],
'Final Grade': ['A', 'B', 'A', 'C', 'A', 'B', 'C', 'A', 'A', 'B']
}
df = pd.DataFrame(data)
# Imputation
imputer = SimpleImputer(strategy="mean")
df[['Exam 1 Score', 'Exam 2 Score', 'Exam 3 Score']] = imputer.fit_transform(df[['Exam 1 Score', 'Exam
2 Score', 'Exam 3 Score']])
print("Imputation : ")
print(df)
# Anomaly Detection
z_scores = stats.zscore(df[['Exam 1 Score', 'Exam 2 Score', 'Exam 3 Score']])
threshold = 3
outliers = (abs(z_scores) > threshold).any(axis=1)
df['Is Outlier'] = outliers
print("Anomaly detection : ")
print(df)
# Standardization
scaler = StandardScaler()
df[['Exam 1 Score', 'Exam 2 Score', 'Exam 3 Score']] = scaler.fit_transform(df[['Exam 1 Score', 'Exam 2
Score', 'Exam 3 Score']])
print("Standardization : ")
print(df)
#Normalization
scaler = MinMaxScaler()
df[['Exam 1 Score', 'Exam 2 Score', 'Exam 3 Score']] = scaler.fit_transform(df[['Exam 1 Score', 'Exam 2
Score', 'Exam 3 Score']])
print("Normalization : ")
print(df)




2.DESCENT

import numpy as np
import matplotlib.pyplot as plt
# Objective function to minimize (example: quadratic function)
def objective_function(x):
return x**2 + 5*x + 10
# Gradient of the objective function
def gradient(x):
return 2*x + 5
# Gradient Descent algorithm
def gradient_descent(initial_x, learning_rate, num_iterations):
x = initial_x
x_history = [x]
for _ in range(num_iterations):
x -= learning_rate * gradient(x)
x_history.append(x)
return x, x_history
# Sample data
sample_data = np.array([-4, -2, 1, 3, 6])
# Hyperparameters
initial_x = 3.0
learning_rate = 0.1
num_iterations = 20
# Perform Gradient Descent
final_x, x_history = gradient_descent(initial_x, learning_rate, num_iterations)
# Print the result
print("Optimal x:", final_x)
print("Optimal value of the objective function:", objective_function(final_x))
# Plot the objective function and the optimization path
x_vals = np.linspace(-5, 5, 400)
y_vals = objective_function(x_vals)
plt.plot(x_vals, y_vals, label='Objective Function')
plt.scatter(x_history, [objective_function(x) for x in x_history], color='red', label='Optimization Path')
plt.xlabel('x')
plt.ylabel('Objective Function Value')
plt.legend()
plt.title('Gradient Descent Optimization')
plt.show()
        
        
        
        
3. linearregression
        
        
import pandas as pd
import numpy as np
import math
import operator
import matplotlib.pyplot as plt
import io
file_path = "D:\\Aaryash's Documents\\TSEC\\Work\\Sem 7\\ML\\BMI.csv"
data = pd.read_csv(file_path)
print(data.head())
# collecting x & y
X = data['BMI'].values
Y = data['Cholestrol'].values
# calculate mean of x & y using an inbuilt numpy method mean()
mean_x = np.mean(X)
mean_y = np.mean(Y)
sum_x = np.sum(X)
sum_y = np.sum(Y)
print(f'x={sum_x} y={sum_y}')
# total no.of input values
n = len(X)
# using the formula to calculate m & c
numer = 0
denom = 0
for i in range(n):
numer += (X[i] - mean_x) * (Y[i] - mean_y)
denom += (X[i] - mean_x) ** 2
b1 = numer / denom
b0 = (sum_y - (b1 * sum_x))/n
print (f'b0 = {b0} \nb1 = {b1}')
# plotting values and regression line
max_x = np.max(X) + 20
min_x = np.min(Y) - 100
# calculating line values x and y
x = np.linspace (min_x, max_x, 100)
y = b0 + b1 * x
plt.plot(x, y, color='#58b970', label='Regression Line')
plt.scatter(X, Y, c='#ef5423', label='data points')
plt.xlabel('BMI')
plt.ylabel('Cholestrol')
plt.legend()
plt.show()
new_x = 23
y_pred = b1*new_x + b0
print(f'Cholestrol Predicted for BMI value {new_x} is {y_pred}â€™)






import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
df = pd.DataFrame({'age': [22,25,47,52,
46,56,55,60,62,61,18,28,27,29,49,55,25,58,19,18,21,26,40,45,50,54,23],
'bought_insurance':[0,0,1,0,1,1,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0]})
test = df.sample(7)
train = df[~df.isin(test)]
train.dropna(inplace = True)
def sigmoid(x):
return 1/(1+np.exp(-x))
def square_loss(y_pred, target):
t = y_pred - target
return np.mean(pow(t,2))
X_tr, y_tr = train.age, train["bought_insurance"]
X_te, y_te = test.age, test["bought_insurance"]
lr = 0.01 #learning late
W = np.random.uniform(0,1) # colom 1
b = 0.1
for i in range(10000):
z = np.dot(X_tr, W) + b
y_pred = sigmoid(z)
l = square_loss(y_pred, y_tr)
gradient_W = np.dot((y_pred-y_tr).T, X_tr)/X_tr.shape[0]
gradient_b = np.mean(y_pred-y_tr)
W = W - lr * gradient_W
b = b - lr* gradient_b
for i in range(len(X_te)):
r = sigmoid(np.dot(X_te, W) + b)
for i in r:
print(i)




5.. decision


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('fivethirtyeight')
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline

data = pd.read_csv('train.csv')

data.head(2)

data.isnull().sum()

f, ax=plt.subplots(1, 2, figsize=(18,8))
data['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[
ax[0].set_title('Survived')
ax[0].set_ylabel('')
sns.countplot(x='Survived', data=data, ax=ax[1])
ax[1].set_title('Survived')
plt.show()


data.groupby(['Sex','Survived'])['Survived'].count()

f, ax = plt.subplots(1,2,figsize=(18,8))
data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])
ax[0].set_title('Survived vs Sex')
sns.countplot(x='Sex',hue='Survived', data=data, ax=ax[1])
ax[1].set_title('Survived vs Dead')
plt.show()





6. svm


# Load the important packages
from sklearn.datasets import load_breast_cancer
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.svm import SVC
# Load the datasets
cancer = load_breast_cancer()
X = cancer.data[:, :2]
y = cancer.target
#Build the model
svm = SVC(kernel="rbf", gamma=0.5, C=1.0)
# Trained the model
svm.fit(X, y)
# Plot Decision Boundary
DecisionBoundaryDisplay.from_estimator(
svm,
X,
response_method="predict",
cmap=plt.cm.Spectral,
alpha=0.8,
xlabel=cancer.feature_names[0],
ylabel=cancer.feature_names[1],
)
# Scatter plot
plt.scatter(X[:, 0], X[:, 1],
c=y,
s=20, edgecolors="k")
plt.show(
        
        
        
        

	</pre>
</body>

</html>